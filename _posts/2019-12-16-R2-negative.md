---
title: Can R<sup>2</sup> value ever be negative? 
author: Akshay Adlakha & Akshaykumar Rao
date: 2020-12-15 08:10:00 +0800
categories: [Blogging, Tutorial]
tags: [writing]
math: true
mermaid: true
---


## What is R<sup>2</sup>?

In a regression model, R<sup>2</sup> determines the proportion of variance in the dependent variable that can be explained by the independent variables. To know more about R-squared and it's limiations, refer to [this](https://thinkdatascience.github.io/posts/R2andAdjustedR2/) link.

$$ \sum_{n=1}^\infty 1/n^2 = \frac{\pi^2}{6} $$

R^2 is given by below formula:

$$ R^2 = 1 - {SS_{Regression} \over SS_{Total}} $$  

or  

$$ R^2 = 1 - {{\sum (y_i - y_Prediction)^2} \over {\sum (y_i - \bar y)^2}} $$


Where,  
       \\(y_i\\) = each data point  
       \\(y_{Prediction}\\) = Value predicted by the regression model  
       \\(\bar y\\) = mean value of y's  


## What is the range of values R<sup>2</sup> can take?  
Most books say that R-squared value is always between 0 and 1. However, this can't be further from the truth. The ratio of the sum of squared regression error to the sum of squared total error is always postive. Hence, the lowest value this ratio can take is 0 when sum of squared regression error is 0 in which case, R<sup>2</sup> is 1. This is the maximum value R<sup>2</sup> can take.  
R<sup>2</sup> is zero when the model's prediction is same as predicting mean. What if the model's predictions are worse than predicting the mean value ? In this case the models predictions are too far away from the acual value. Therefore, the ratio of sum sqaured regression error to sum squared total error is greater than 1, making R<sup>2</sup> negative.



